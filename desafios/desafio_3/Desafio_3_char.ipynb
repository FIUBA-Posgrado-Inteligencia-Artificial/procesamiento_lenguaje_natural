{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pickle\n",
        "import random\n",
        "# descargar de textos.info\n",
        "import urllib.request\n",
        "\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from keras.layers import (LSTM, BatchNormalization, CategoryEncoding, Dense,\n",
        "                          Dropout, Embedding, Input, SimpleRNN,\n",
        "                          TimeDistributed)\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import to_categorical\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import pad_sequences  # se utilizará para padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Se utilizará un dataset ligero de spam de emails: https://www.kaggle.com/datasets/tapakah68/email-spam-classification\n",
        "\n",
        "Primero descomprimimos el fichero y leemos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "7amy6uUaBLVD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"unzip\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q email_spam.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "6v_ickFwBJTy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the secrets to SUCCESS</td>\n",
              "      <td>Hi James,  Have you claim your complimentary g...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You Earned 500 GCLoot Points</td>\n",
              "      <td>alt_text Congratulations, you just earned 500...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Your GitHub launch code</td>\n",
              "      <td>Here's your GitHub launch code, @Mortyj420!   ...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The Virtual Reward Center] Re: ** Clarifications</td>\n",
              "      <td>Hello,   Thank you for contacting the Virtual ...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10-1 MLB Expert Inside, Plus Everything You Ne...</td>\n",
              "      <td>Hey Prachanda Rawal,  Today's newsletter is Ja...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Your application for the position of  Child Pr...</td>\n",
              "      <td>Dear Maryam,      I would like to thank you fo...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Your Kilimall Account is Ready - Shopping Now!</td>\n",
              "      <td>Dear Customer,  Welcome to Kilimall, Thanks so...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Your Steam account: Access from new web or mob...</td>\n",
              "      <td>Dear vladis163rus, Here is the Steam Guard cod...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Your uploaded document is rejected</td>\n",
              "      <td>View In Browser | Log in      Skrill logo Mone...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>You've Earned a Reward from Bard Explorers India</td>\n",
              "      <td>You've received a gift! Sign in to your Bard E...</td>\n",
              "      <td>not spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0                              the secrets to SUCCESS   \n",
              "1                        You Earned 500 GCLoot Points   \n",
              "2                             Your GitHub launch code   \n",
              "3   [The Virtual Reward Center] Re: ** Clarifications   \n",
              "4   10-1 MLB Expert Inside, Plus Everything You Ne...   \n",
              "..                                                ...   \n",
              "79  Your application for the position of  Child Pr...   \n",
              "80     Your Kilimall Account is Ready - Shopping Now!   \n",
              "81  Your Steam account: Access from new web or mob...   \n",
              "82                 Your uploaded document is rejected   \n",
              "83   You've Earned a Reward from Bard Explorers India   \n",
              "\n",
              "                                                 text      type  \n",
              "0   Hi James,  Have you claim your complimentary g...      spam  \n",
              "1    alt_text Congratulations, you just earned 500...  not spam  \n",
              "2   Here's your GitHub launch code, @Mortyj420!   ...  not spam  \n",
              "3   Hello,   Thank you for contacting the Virtual ...  not spam  \n",
              "4   Hey Prachanda Rawal,  Today's newsletter is Ja...      spam  \n",
              "..                                                ...       ...  \n",
              "79  Dear Maryam,      I would like to thank you fo...  not spam  \n",
              "80  Dear Customer,  Welcome to Kilimall, Thanks so...  not spam  \n",
              "81  Dear vladis163rus, Here is the Steam Guard cod...  not spam  \n",
              "82  View In Browser | Log in      Skrill logo Mone...  not spam  \n",
              "83  You've received a gift! Sign in to your Bard E...  not spam  \n",
              "\n",
              "[84 rows x 3 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe_spam = pd.read_csv(\"email_spam.csv\", encoding='latin-1')\n",
        "# Reemplazar '\\r' por un string vacío en todas las columnas\n",
        "dataframe_spam = dataframe_spam.replace({'\\r': ' ', '\\n': ' ', \"\\?\\?\": ''}, regex=True)\n",
        "dataframe_spam.head(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "WBE0sSYuB-E6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the secrets to SUCCESS Hi James,  Have you cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You Earned 500 GCLoot Points  alt_text Congra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Your GitHub launch code Here's your GitHub la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The Virtual Reward Center] Re: ** Clarificati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10-1 MLB Expert Inside, Plus Everything You Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Your application for the position of  Child Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Your Kilimall Account is Ready - Shopping Now!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Your Steam account: Access from new web or mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Your uploaded document is rejected View In Bro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>You've Earned a Reward from Bard Explorers Ind...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text\n",
              "0    the secrets to SUCCESS Hi James,  Have you cl...\n",
              "1    You Earned 500 GCLoot Points  alt_text Congra...\n",
              "2    Your GitHub launch code Here's your GitHub la...\n",
              "3   [The Virtual Reward Center] Re: ** Clarificati...\n",
              "4   10-1 MLB Expert Inside, Plus Everything You Ne...\n",
              "..                                                ...\n",
              "79  Your application for the position of  Child Pr...\n",
              "80  Your Kilimall Account is Ready - Shopping Now!...\n",
              "81  Your Steam account: Access from new web or mob...\n",
              "82  Your uploaded document is rejected View In Bro...\n",
              "83  You've Earned a Reward from Bard Explorers Ind...\n",
              "\n",
              "[84 rows x 1 columns]"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe_spam_title = dataframe_spam[\"title\"]\n",
        "dataframe_spam_text = dataframe_spam[\"text\"]\n",
        "dataframe_spam = pd.DataFrame({'Text': dataframe_spam_title + ' ' + dataframe_spam_text})\n",
        "dataframe_spam.head(300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " the secrets to SUCCESS Hi James,  Have you claim your complimentary gift yet?  I've compiled in here a special astrology gift that predicts everything about you in the future?  This is your enabler to take the correct actions now.  >> Click here to claim your copy now >>  Claim yours now, and thank me later.   Love, Heather  You Earned 500 GCLoot Points  alt_text Congratulations, you just earned 500   You completed the following offer:  View Points History To stop recieving notifications when y\n"
          ]
        }
      ],
      "source": [
        "corpus = ' '.join(dataframe_spam['Text'])\n",
        "print(corpus[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 150 # criterio a mano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "VwTK6xgLJd8q"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "len(chars_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "PwGVSKOiJ5bj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 88,\n",
              " 87,\n",
              " 51,\n",
              " 7,\n",
              " 87,\n",
              " 66,\n",
              " 88,\n",
              " 19,\n",
              " 66,\n",
              " 84,\n",
              " 19,\n",
              " 57,\n",
              " 91,\n",
              " 17,\n",
              " 17,\n",
              " 46,\n",
              " 57,\n",
              " 57,\n",
              " 19,\n",
              " 86,\n",
              " 96,\n",
              " 19,\n",
              " 76,\n",
              " 6,\n",
              " 25,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 19,\n",
              " 19,\n",
              " 86,\n",
              " 6,\n",
              " 38,\n",
              " 87,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 51,\n",
              " 5,\n",
              " 6,\n",
              " 96,\n",
              " 25,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 25,\n",
              " 63,\n",
              " 5,\n",
              " 96,\n",
              " 25,\n",
              " 87,\n",
              " 15,\n",
              " 66,\n",
              " 6,\n",
              " 7,\n",
              " 65,\n",
              " 19,\n",
              " 83,\n",
              " 96,\n",
              " 90,\n",
              " 66,\n",
              " 19,\n",
              " 65,\n",
              " 87,\n",
              " 66,\n",
              " 94,\n",
              " 19,\n",
              " 19,\n",
              " 52,\n",
              " 43,\n",
              " 38,\n",
              " 87,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 25,\n",
              " 63,\n",
              " 96,\n",
              " 5,\n",
              " 87,\n",
              " 21,\n",
              " 19,\n",
              " 96,\n",
              " 15,\n",
              " 19,\n",
              " 82,\n",
              " 87,\n",
              " 7,\n",
              " 87,\n",
              " 19,\n",
              " 6,\n",
              " 19,\n",
              " 88,\n",
              " 63,\n",
              " 87,\n",
              " 51,\n",
              " 96,\n",
              " 6,\n",
              " 5,\n",
              " 19,\n",
              " 6,\n",
              " 88,\n",
              " 66,\n",
              " 7,\n",
              " 84,\n",
              " 5,\n",
              " 84,\n",
              " 83,\n",
              " 65,\n",
              " 19,\n",
              " 83,\n",
              " 96,\n",
              " 90,\n",
              " 66,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 6,\n",
              " 66,\n",
              " 19,\n",
              " 63,\n",
              " 7,\n",
              " 87,\n",
              " 21,\n",
              " 96,\n",
              " 51,\n",
              " 66,\n",
              " 88,\n",
              " 19,\n",
              " 87,\n",
              " 38,\n",
              " 87,\n",
              " 7,\n",
              " 65,\n",
              " 66,\n",
              " 82,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 6,\n",
              " 26,\n",
              " 84,\n",
              " 70,\n",
              " 66,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 96,\n",
              " 15,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 90,\n",
              " 70,\n",
              " 66,\n",
              " 70,\n",
              " 7,\n",
              " 87,\n",
              " 94,\n",
              " 19,\n",
              " 19,\n",
              " 47,\n",
              " 82,\n",
              " 96,\n",
              " 88,\n",
              " 19,\n",
              " 96,\n",
              " 88,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 87,\n",
              " 15,\n",
              " 6,\n",
              " 26,\n",
              " 5,\n",
              " 87,\n",
              " 7,\n",
              " 19,\n",
              " 66,\n",
              " 84,\n",
              " 19,\n",
              " 66,\n",
              " 6,\n",
              " 61,\n",
              " 87,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 7,\n",
              " 7,\n",
              " 87,\n",
              " 51,\n",
              " 66,\n",
              " 19,\n",
              " 6,\n",
              " 51,\n",
              " 66,\n",
              " 96,\n",
              " 84,\n",
              " 15,\n",
              " 88,\n",
              " 19,\n",
              " 15,\n",
              " 84,\n",
              " 102,\n",
              " 78,\n",
              " 19,\n",
              " 19,\n",
              " 92,\n",
              " 92,\n",
              " 19,\n",
              " 17,\n",
              " 5,\n",
              " 96,\n",
              " 51,\n",
              " 61,\n",
              " 19,\n",
              " 82,\n",
              " 87,\n",
              " 7,\n",
              " 87,\n",
              " 19,\n",
              " 66,\n",
              " 84,\n",
              " 19,\n",
              " 51,\n",
              " 5,\n",
              " 6,\n",
              " 96,\n",
              " 25,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 63,\n",
              " 65,\n",
              " 19,\n",
              " 15,\n",
              " 84,\n",
              " 102,\n",
              " 19,\n",
              " 92,\n",
              " 92,\n",
              " 19,\n",
              " 19,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 96,\n",
              " 25,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 88,\n",
              " 19,\n",
              " 15,\n",
              " 84,\n",
              " 102,\n",
              " 89,\n",
              " 19,\n",
              " 6,\n",
              " 15,\n",
              " 21,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 6,\n",
              " 15,\n",
              " 61,\n",
              " 19,\n",
              " 25,\n",
              " 87,\n",
              " 19,\n",
              " 5,\n",
              " 6,\n",
              " 66,\n",
              " 87,\n",
              " 7,\n",
              " 78,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 62,\n",
              " 84,\n",
              " 38,\n",
              " 87,\n",
              " 89,\n",
              " 19,\n",
              " 86,\n",
              " 87,\n",
              " 6,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 7,\n",
              " 19,\n",
              " 19,\n",
              " 20,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 46,\n",
              " 6,\n",
              " 7,\n",
              " 15,\n",
              " 87,\n",
              " 21,\n",
              " 19,\n",
              " 35,\n",
              " 67,\n",
              " 67,\n",
              " 19,\n",
              " 81,\n",
              " 17,\n",
              " 62,\n",
              " 84,\n",
              " 84,\n",
              " 66,\n",
              " 19,\n",
              " 0,\n",
              " 84,\n",
              " 96,\n",
              " 15,\n",
              " 66,\n",
              " 88,\n",
              " 19,\n",
              " 19,\n",
              " 6,\n",
              " 5,\n",
              " 66,\n",
              " 103,\n",
              " 66,\n",
              " 87,\n",
              " 23,\n",
              " 66,\n",
              " 19,\n",
              " 17,\n",
              " 84,\n",
              " 15,\n",
              " 83,\n",
              " 7,\n",
              " 6,\n",
              " 66,\n",
              " 70,\n",
              " 5,\n",
              " 6,\n",
              " 66,\n",
              " 96,\n",
              " 84,\n",
              " 15,\n",
              " 88,\n",
              " 89,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 93,\n",
              " 70,\n",
              " 88,\n",
              " 66,\n",
              " 19,\n",
              " 87,\n",
              " 6,\n",
              " 7,\n",
              " 15,\n",
              " 87,\n",
              " 21,\n",
              " 19,\n",
              " 35,\n",
              " 67,\n",
              " 67,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 20,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 25,\n",
              " 63,\n",
              " 5,\n",
              " 87,\n",
              " 66,\n",
              " 87,\n",
              " 21,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 90,\n",
              " 84,\n",
              " 5,\n",
              " 5,\n",
              " 84,\n",
              " 102,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 84,\n",
              " 90,\n",
              " 90,\n",
              " 87,\n",
              " 7,\n",
              " 40,\n",
              " 19,\n",
              " 19,\n",
              " 48,\n",
              " 96,\n",
              " 87,\n",
              " 102,\n",
              " 19,\n",
              " 0,\n",
              " 84,\n",
              " 96,\n",
              " 15,\n",
              " 66,\n",
              " 88,\n",
              " 19,\n",
              " 86,\n",
              " 96,\n",
              " 88,\n",
              " 66,\n",
              " 84,\n",
              " 7,\n",
              " 65,\n",
              " 19,\n",
              " 47,\n",
              " 84,\n",
              " 19,\n",
              " 88,\n",
              " 66,\n",
              " 84,\n",
              " 63,\n",
              " 19,\n",
              " 7,\n",
              " 87,\n",
              " 51,\n",
              " 96,\n",
              " 87,\n",
              " 38,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 15,\n",
              " 84,\n",
              " 66,\n",
              " 96,\n",
              " 90,\n",
              " 96,\n",
              " 51,\n",
              " 6,\n",
              " 66,\n",
              " 96,\n",
              " 84,\n",
              " 15,\n",
              " 88,\n",
              " 19,\n",
              " 102,\n",
              " 82,\n",
              " 87,\n",
              " 15,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 87,\n",
              " 6,\n",
              " 7,\n",
              " 15,\n",
              " 19,\n",
              " 63,\n",
              " 84,\n",
              " 96,\n",
              " 15,\n",
              " 66,\n",
              " 88,\n",
              " 89,\n",
              " 19,\n",
              " 63,\n",
              " 5,\n",
              " 87,\n",
              " 6,\n",
              " 88,\n",
              " 87,\n",
              " 19,\n",
              " 38,\n",
              " 96,\n",
              " 88,\n",
              " 96,\n",
              " 66,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 63,\n",
              " 7,\n",
              " 84,\n",
              " 90,\n",
              " 96,\n",
              " 5,\n",
              " 87,\n",
              " 19,\n",
              " 6,\n",
              " 15,\n",
              " 21,\n",
              " 19,\n",
              " 51,\n",
              " 5,\n",
              " 96,\n",
              " 51,\n",
              " 61,\n",
              " 19,\n",
              " 73,\n",
              " 0,\n",
              " 7,\n",
              " 87,\n",
              " 90,\n",
              " 87,\n",
              " 7,\n",
              " 87,\n",
              " 15,\n",
              " 51,\n",
              " 87,\n",
              " 88,\n",
              " 73,\n",
              " 19,\n",
              " 66,\n",
              " 84,\n",
              " 19,\n",
              " 51,\n",
              " 82,\n",
              " 6,\n",
              " 15,\n",
              " 83,\n",
              " 87,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 88,\n",
              " 87,\n",
              " 66,\n",
              " 66,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 78,\n",
              " 19,\n",
              " 19,\n",
              " 9,\n",
              " 84,\n",
              " 84,\n",
              " 25,\n",
              " 19,\n",
              " 79,\n",
              " 55,\n",
              " 67,\n",
              " 99,\n",
              " 89,\n",
              " 19,\n",
              " 79,\n",
              " 55,\n",
              " 66,\n",
              " 82,\n",
              " 19,\n",
              " 95,\n",
              " 5,\n",
              " 84,\n",
              " 84,\n",
              " 7,\n",
              " 89,\n",
              " 19,\n",
              " 47,\n",
              " 84,\n",
              " 102,\n",
              " 87,\n",
              " 7,\n",
              " 19,\n",
              " 99,\n",
              " 19,\n",
              " 19,\n",
              " 17,\n",
              " 82,\n",
              " 96,\n",
              " 15,\n",
              " 6,\n",
              " 19,\n",
              " 86,\n",
              " 84,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 42,\n",
              " 84,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 17,\n",
              " 96,\n",
              " 66,\n",
              " 65,\n",
              " 89,\n",
              " 19,\n",
              " 99,\n",
              " 99,\n",
              " 19,\n",
              " 17,\n",
              " 6,\n",
              " 15,\n",
              " 66,\n",
              " 84,\n",
              " 15,\n",
              " 19,\n",
              " 9,\n",
              " 84,\n",
              " 6,\n",
              " 21,\n",
              " 19,\n",
              " 19,\n",
              " 47,\n",
              " 88,\n",
              " 96,\n",
              " 25,\n",
              " 19,\n",
              " 57,\n",
              " 82,\n",
              " 6,\n",
              " 19,\n",
              " 47,\n",
              " 88,\n",
              " 70,\n",
              " 96,\n",
              " 89,\n",
              " 19,\n",
              " 42,\n",
              " 84,\n",
              " 102,\n",
              " 5,\n",
              " 84,\n",
              " 84,\n",
              " 15,\n",
              " 89,\n",
              " 19,\n",
              " 86,\n",
              " 84,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 42,\n",
              " 84,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 19,\n",
              " 91,\n",
              " 15,\n",
              " 88,\n",
              " 70,\n",
              " 26,\n",
              " 88,\n",
              " 51,\n",
              " 7,\n",
              " 96,\n",
              " 26,\n",
              " 87,\n",
              " 19,\n",
              " 19,\n",
              " 20,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 81,\n",
              " 96,\n",
              " 66,\n",
              " 86,\n",
              " 70,\n",
              " 26,\n",
              " 19,\n",
              " 5,\n",
              " 6,\n",
              " 70,\n",
              " 15,\n",
              " 51,\n",
              " 82,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 21,\n",
              " 87,\n",
              " 19,\n",
              " 86,\n",
              " 87,\n",
              " 7,\n",
              " 87,\n",
              " 43,\n",
              " 88,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 7,\n",
              " 19,\n",
              " 81,\n",
              " 96,\n",
              " 66,\n",
              " 86,\n",
              " 70,\n",
              " 26,\n",
              " 19,\n",
              " 5,\n",
              " 6,\n",
              " 70,\n",
              " 15,\n",
              " 51,\n",
              " 82,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 21,\n",
              " 87,\n",
              " 89,\n",
              " 19,\n",
              " 36,\n",
              " 53,\n",
              " 84,\n",
              " 7,\n",
              " 66,\n",
              " 65,\n",
              " 93,\n",
              " 14,\n",
              " 55,\n",
              " 67,\n",
              " 50,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 6,\n",
              " 15,\n",
              " 19,\n",
              " 84,\n",
              " 51,\n",
              " 66,\n",
              " 84,\n",
              " 51,\n",
              " 6,\n",
              " 66,\n",
              " 19,\n",
              " 88,\n",
              " 66,\n",
              " 6,\n",
              " 15,\n",
              " 21,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 15,\n",
              " 87,\n",
              " 23,\n",
              " 66,\n",
              " 19,\n",
              " 66,\n",
              " 84,\n",
              " 19,\n",
              " 6,\n",
              " 19,\n",
              " 7,\n",
              " 84,\n",
              " 51,\n",
              " 61,\n",
              " 87,\n",
              " 66,\n",
              " 19,\n",
              " 19,\n",
              " 17,\n",
              " 84,\n",
              " 15,\n",
              " 66,\n",
              " 96,\n",
              " 15,\n",
              " 70,\n",
              " 87,\n",
              " 19,\n",
              " 88,\n",
              " 96,\n",
              " 83,\n",
              " 15,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 70,\n",
              " 63,\n",
              " 19,\n",
              " 90,\n",
              " 84,\n",
              " 7,\n",
              " 19,\n",
              " 81,\n",
              " 96,\n",
              " 66,\n",
              " 86,\n",
              " 70,\n",
              " 26,\n",
              " 19,\n",
              " 26,\n",
              " 65,\n",
              " 19,\n",
              " 87,\n",
              " 15,\n",
              " 66,\n",
              " 87,\n",
              " 7,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 21,\n",
              " 87,\n",
              " 19,\n",
              " 26,\n",
              " 87,\n",
              " 5,\n",
              " 84,\n",
              " 102,\n",
              " 40,\n",
              " 19,\n",
              " 19,\n",
              " 69,\n",
              " 99,\n",
              " 67,\n",
              " 55,\n",
              " 14,\n",
              " 69,\n",
              " 79,\n",
              " 67,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 32,\n",
              " 63,\n",
              " 87,\n",
              " 15,\n",
              " 19,\n",
              " 81,\n",
              " 96,\n",
              " 66,\n",
              " 86,\n",
              " 70,\n",
              " 26,\n",
              " 19,\n",
              " 1,\n",
              " 47,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 48,\n",
              " 96,\n",
              " 7,\n",
              " 66,\n",
              " 70,\n",
              " 6,\n",
              " 5,\n",
              " 19,\n",
              " 9,\n",
              " 87,\n",
              " 102,\n",
              " 6,\n",
              " 7,\n",
              " 21,\n",
              " 19,\n",
              " 17,\n",
              " 87,\n",
              " 15,\n",
              " 66,\n",
              " 87,\n",
              " 7,\n",
              " 37,\n",
              " 19,\n",
              " 9,\n",
              " 87,\n",
              " 40,\n",
              " 19,\n",
              " 54,\n",
              " 54,\n",
              " 19,\n",
              " 17,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 96,\n",
              " 90,\n",
              " 96,\n",
              " 51,\n",
              " 6,\n",
              " 66,\n",
              " 96,\n",
              " 84,\n",
              " 15,\n",
              " 88,\n",
              " 19,\n",
              " 86,\n",
              " 87,\n",
              " 5,\n",
              " 5,\n",
              " 84,\n",
              " 89,\n",
              " 19,\n",
              " 19,\n",
              " 19,\n",
              " 47,\n",
              " 82,\n",
              " 6,\n",
              " 15,\n",
              " 61,\n",
              " 19,\n",
              " 65,\n",
              " 84,\n",
              " 70,\n",
              " 19,\n",
              " 90,\n",
              " 84,\n",
              " 7,\n",
              " 19,\n",
              " 51,\n",
              " 84,\n",
              " 15,\n",
              " 66,\n",
              " 6,\n",
              " 51,\n",
              " 66,\n",
              " 96,\n",
              " 15,\n",
              " 83,\n",
              " 19,\n",
              " 66,\n",
              " 82,\n",
              " 87,\n",
              " 19,\n",
              " 48,\n",
              " 96,\n",
              " 7,\n",
              " 66,\n",
              " 70,\n",
              " 6,\n",
              " 5,\n",
              " 19,\n",
              " 9,\n",
              " 87,\n",
              " 102,\n",
              " 6]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.2\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "KFAyA4zCWE-5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(59635, 150)"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "qcKRl70HFTzG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([19, 66, 82, 87, 19, 88, 87, 51,  7, 87])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "TVpLCKSZFXZO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([66, 82, 87, 19, 88, 87, 51,  7, 87, 66])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "wOFCR-KqbW1N"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(chars_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia.\n",
        "\n",
        "Para el el desafío, añadimos una capa mas de SimplRNN para ver cómo se comporta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Zd2OkfQYs2Q7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lorda\\Source\\Repos\\CEIA\\len-nat\\.env\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">89,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,250</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,355</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_7 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)      │        \u001b[38;5;34m89,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_8 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)      │       \u001b[38;5;34m125,250\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m)      │        \u001b[38;5;34m26,355\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,605</span> (939.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,605\u001b[0m (939.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,605</span> (939.86 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m240,605\u001b[0m (939.86 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(250, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))\n",
        "model.add(SimpleRNN(250, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"char_my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 3.3217\n",
            " mean perplexity: 14.198404226643863 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 383ms/step - loss: 3.3203\n",
            "Epoch 2/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 2.4848\n",
            " mean perplexity: 12.259701969592728 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 374ms/step - loss: 2.4845\n",
            "Epoch 3/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - loss: 2.2428\n",
            " mean perplexity: 11.594906192103503 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 375ms/step - loss: 2.2426\n",
            "Epoch 4/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - loss: 2.0869\n",
            " mean perplexity: 10.709891157372345 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 381ms/step - loss: 2.0868\n",
            "Epoch 5/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - loss: 1.9755\n",
            " mean perplexity: 10.844710796356145 \n",
            "\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 377ms/step - loss: 1.9754\n",
            "Epoch 6/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - loss: 1.8921\n",
            " mean perplexity: 10.82927217697762 \n",
            "\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 373ms/step - loss: 1.8920\n",
            "Epoch 7/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - loss: 1.8322\n",
            " mean perplexity: 11.45228448889786 \n",
            "\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 361ms/step - loss: 1.8322\n",
            "Epoch 8/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - loss: 1.7824\n",
            " mean perplexity: 12.143988732913297 \n",
            "\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 357ms/step - loss: 1.7823\n",
            "Epoch 9/20\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - loss: 1.7408\n",
            " mean perplexity: 11.439397896585447 \n",
            "\n",
            "Stopping training...\n",
            "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 357ms/step - loss: 1.7408\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIdklEQVR4nO3de1hUdeIG8PfMDHeY4X5TLuINRQUUVLxULqSZa1qbmpmSl9r2Z1c3U2tTd6u1dttqW03TzFtlbZlmVpaipa6mAo53UJGryE2B4SK3mfP7A5ikREFmOGdm3s/znKdnbof3mMLL+Z7z/QqiKIogIiIikjGF1AGIiIiIboWFhYiIiGSPhYWIiIhkj4WFiIiIZI+FhYiIiGSPhYWIiIhkj4WFiIiIZI+FhYiIiGRPJXUAUzEYDMjPz4ebmxsEQZA6DhEREbWBKIqoqKhAYGAgFIrWz6NYTWHJz89HUFCQ1DGIiIjoNuTm5qJr166tvm41hcXNzQ1A4wGr1WqJ0xAREVFb6HQ6BAUFGX+Ot8ZqCkvzMJBarWZhISIisjC3upyDF90SERGR7LGwEBERkeyxsBAREZHssbAQERGR7LGwEBERkeyxsBAREZHssbAQERGR7LGwEBERkeyxsBAREZHssbAQERGR7LGwEBERkeyxsBAREZHssbDcRE29HhsOZuGJTSlo0BukjkNERGSzrGa1ZnNQKQS8tescyq/VIzWnDIO7eUodiYiIyCbxDMtNqJQKjOrtAwBIOlsocRoiIiLbxcJyC/F9/AAAu1lYiIiIJMPCcgt39vaBSiEgo7gKmSVVUschIiKySSwst6B2tMOQsMZrVzgsREREJA0WljaID+ewEBERkZRYWNogoek6lqNZpSivrpc4DRERke1hYWmDYC9n9PJzhd4g4sdzRVLHISIisjksLG30y91CLCxERESdjYWljRL6+AIAfkwvQj1nvSUiIupULCxtFBXkAU8Xe1TUNOBo5lWp4xAREdkUFpY2UioE/C688SwLh4WIiIg6FwtLOzQPCyWlFUIURYnTEBER2Q4WlnYY2dMH9koFsq9UI6O4Uuo4RERENoOFpR1cHFQY2t0LALDrDIeFiIiIOku7C8u+ffswfvx4BAYGQhAEbNu2rdX3PvHEExAEAe+8884t97tixQqEhobC0dERQ4YMwZEjR9obrVPc3TwsxFlviYiIOk27C0tVVRUiIyOxYsWKm75v69at+PnnnxEYGHjLfX722WeYN28elixZgtTUVERGRmLMmDEoKpLfWYzfNc3HkppTiiuVtRKnISIisg3tLixjx47Fq6++ivvvv7/V91y6dAlPPfUUPv74Y9jZ2d1yn2+99RYee+wxzJw5E3379sWqVavg7OyMDz/8sL3xzK6LuxP6BKhhEIG96cVSxyEiIrIJJr+GxWAwYPr06Zg/fz4iIiJu+f66ujqkpKQgISHhl1AKBRISEnDo0CFTxzMJDgsRERF1LpMXljfeeAMqlQpPP/10m95fUlICvV4PPz+/Fs/7+fmhoKCg1c/V1tZCp9O12DpL8zT9+84Vo7ZB32lfl4iIyFaZtLCkpKTg3//+N9avXw9BEEy5699YtmwZNBqNcQsKCjLr17te/y4a+Lg5oKpOj8MXOestERGRuZm0sOzfvx9FRUUIDg6GSqWCSqVCdnY2/vznPyM0NPSGn/H29oZSqURhYcvhlcLCQvj7+7f6tRYtWoTy8nLjlpuba8pDuSmFQkC8cdZbDgsRERGZm0kLy/Tp03HixAlotVrjFhgYiPnz5+P777+/4Wfs7e0xaNAgJCUlGZ8zGAxISkpCXFxcq1/LwcEBarW6xdaZEpqGhZLOFnHWWyIiIjNTtfcDlZWVuHDhgvFxZmYmtFotPD09ERwcDC8vrxbvt7Ozg7+/P3r37m18Lj4+Hvfffz+efPJJAMC8efOQmJiImJgYDB48GO+88w6qqqowc+bM2z0usxvewxsOKgUulV1DWkEF+gR0bmEiIiKyJe0uLMnJyRg1apTx8bx58wAAiYmJWL9+fZv2kZGRgZKSEuPjKVOmoLi4GIsXL0ZBQQGioqKwc+fO31yIKydO9kqM6OGNpLQiJJ0tZGEhIiIyI0G0kvEMnU4HjUaD8vLyThse+uRwDl7cehKRQe74au7wTvmaRERE1qStP7+5llAHxDfNx3I8twxFFTUSpyEiIrJeLCwd4Kd2xICuGgDA3jT5LSNARERkLVhYOig+vPE6m91nWViIiIjMhYWlgxL6Ng4L7T9fjJp6znpLRERkDiwsHdQ3QI1AjSNq6g04mFFy6w8QERFRu7GwdJAgCPhdn+ZZbzksREREZA4sLCYQb5z1tpCz3hIREZkBC4sJxIV5wdleiUJdLU5d6rxVo4mIiGwFC4sJONopMbKnNwAuhkhERGQOLCwmYhwWSmNhISIiMjUWFhP5XbgvBAE4dUmHy+XXpI5DRERkVVhYTMTb1QHRQe4AgCTeLURERGRSLCwmdP3dQkRERGQ6LCwmlNBUWP6XcQXVdQ0SpyEiIrIeLCwm1MvPFUGeTqhrMGD/ec56S0REZCosLCYkCIJxMUQOCxEREZkOC4uJNQ8L7UkrgsHAWW+JiIhMgYXFxAZ384SbgwollXXQ5pVJHYeIiMgqsLCYmL1KgTt6+wDgsBAREZGpsLCYQULT6s2cj4WIiMg0WFjM4K5evlAIQFpBBXKvVksdh4iIyOKxsJiBh4s9YkI8AXBYiIiIyBRYWMwkoW/TsFAah4WIiIg6ioXFTJqn6f/54hVU1NRLnIaIiMiysbCYSXcfV3TzdkG9XuSst0RERB3EwmJGzXcL7T7D61iIiIg6goXFjJqHhfamF0HPWW+JiIhuGwuLGcWEeEDjZIfS6nqk5pRKHYeIiMhisbCYkUqpwF1Ns95yWIiIiOj2sbCYWfNiiLs5HwsREdFtY2Exszt7+0ClEJBRXIWskiqp4xAREVkkFhYzUzvaYXC3xllveZaFiIjo9rCwdIJ4DgsRERF1CAtLJ2iej+VoVinKqznrLRERUXuxsHSCEC8X9PR1hd4g4sdzXFuIiIiovVhYOknzsFDSWRYWIiKi9mJh6SR3N63evDe9CPV6g8RpiIiILAsLSyeJCvKAp4s9KmoacDTrqtRxiIiILEq7C8u+ffswfvx4BAYGQhAEbNu2rcXrS5cuRXh4OFxcXODh4YGEhAQcPnz4pvtcunQpBEFosYWHh7c3mqwpFQJG9W48y8JhISIiovZpd2GpqqpCZGQkVqxYccPXe/XqheXLl+PkyZM4cOAAQkNDMXr0aBQXF990vxEREbh8+bJxO3DgQHujyZ5x9eazhRBFLoZIRETUVqr2fmDs2LEYO3Zsq68//PDDLR6/9dZbWLt2LU6cOIH4+PjWg6hU8Pf3b28cizKylw/slQpkX6lGRnElevi6SR2JiIjIIpj1Gpa6ujqsXr0aGo0GkZGRN33v+fPnERgYiLCwMEybNg05OTk3fX9tbS10Ol2LTe5cHVQY2t0LALCbw0JERERtZpbCsmPHDri6usLR0RFvv/02du3aBW9v71bfP2TIEKxfvx47d+7EypUrkZmZiZEjR6KioqLVzyxbtgwajca4BQUFmeNQTK55WCiJs94SERG1mSB24GIKQRCwdetWTJw4scXzVVVVuHz5MkpKSrBmzRrs2bMHhw8fhq+vb5v2W1ZWhpCQELz11luYPXv2Dd9TW1uL2tpa42OdToegoCCUl5dDrVbf7iGZXV5pNUa8sRcKAUj+y93wdLGXOhIREZFkdDodNBrNLX9+m+UMi4uLC3r06IGhQ4di7dq1UKlUWLt2bZs/7+7ujl69euHChQutvsfBwQFqtbrFZgm6ejijT4AaBhHYm8ZhISIiorbolHlYDAZDi7Mht1JZWYmMjAwEBASYMZV0jMNCaRwWIiIiaot2F5bKykpotVpotVoAQGZmJrRaLXJyclBVVYUXX3wRP//8M7Kzs5GSkoJZs2bh0qVLmDRpknEf8fHxWL58ufHx888/j59++glZWVk4ePAg7r//fiiVSkydOrXjRyhDzdP07ztXgtoGvcRpiIiI5K/dtzUnJydj1KhRxsfz5s0DACQmJmLVqlVIS0vDhg0bUFJSAi8vL8TGxmL//v2IiIgwfiYjIwMlJSXGx3l5eZg6dSquXLkCHx8fjBgxAj///DN8fHw6cmyyNaCLBj5uDiiuqMXhi1dxRy/rPE4iIiJT6dBFt3LS1ot25GLhlhP49GguEuNC8NcJ/aSOQ0REJAlJL7qlW2seFtp9toiz3hIREd0CC4tERvTwhoNKgUtl15BW0Pp8M0RERMTCIhkneyVG9GicTI+TyBEREd0cC4uErh8WIiIiotaxsEgovmk+luN5ZSiqqJE4DRERkXyxsEjIT+2I/l00EDnrLRER0U2xsEgsgcNCREREt8TCIrHmYaED50tQU89Zb4mIiG6EhUViEYFqBGgcca1ej0MZV6SOQ0REJEssLBITBMF4lmUXb28mIiK6IRYWGWi+vXkPZ70lIiK6IRYWGYgL84KzvRIFuhqcztdJHYeIiEh2WFhkwNHul1lvd53hsBAREdGvsbDIRELfxmGhpDQWFiIiol9jYZGJ34X7QhCAU5d0KCjnrLdERETXY2GRCW9XB0QFuQPgWRYiIqJfY2GREeOst7yOhYiIqAUWFhlpLiz/y7iC6roGidMQERHJBwuLjPTyc0VXDyfUNRhw4HyJ1HGIiIhkg4VFRgRBMJ5lSeJiiEREREYsLDJjLCxpRTAYOOstERERwMIiO4O7ecLNQYWSyloczyuTOg4REZEssLDIjL1KgTt6+QDgsBAREVEzFhYZal69eTdXbyYiIgLAwiJLo3r7QiEAaQUVyCutljoOERGR5FhYZMjDxR4xIZ4AOCxEREQEsLDIFoeFiIiIfsHCIlPxTbc3/3zxCipq6iVOQ0REJC0WFpnq7uOCbt4uqNeL2M9Zb4mIyMaxsMiUIAiID+ewEBEREcDCImvNw0J704qg56y3RERkw1hYZCwm1AMaJzuUVtcjNadU6jhERESSYWGRMTulAnf1bpz1lsNCRERky1hYZC6eqzcTERGxsMjdnb18oFIIuFBUiaySKqnjEBERSYKFReY0TnYY3K1x1lsOCxERka1iYbEAHBYiIiJb1+7Csm/fPowfPx6BgYEQBAHbtm1r8frSpUsRHh4OFxcXeHh4ICEhAYcPH77lflesWIHQ0FA4OjpiyJAhOHLkSHujWa2Epmn6j2RdRXk1Z70lIiLb0+7CUlVVhcjISKxYseKGr/fq1QvLly/HyZMnceDAAYSGhmL06NEoLi5udZ+fffYZ5s2bhyVLliA1NRWRkZEYM2YMiop4RgEAQrxc0MPXFXqDiB/P8c+EiIhsjyCK4m3PSCYIArZu3YqJEye2+h6dTgeNRoPdu3cjPj7+hu8ZMmQIYmNjsXz5cgCAwWBAUFAQnnrqKSxcuLBNWZq/Tnl5OdRqdbuPRe5e/y4Nq37KwH2RgXh3arTUcYiIiEyirT+/zXoNS11dHVavXg2NRoPIyMhW35OSkoKEhIRfQikUSEhIwKFDh1rdd21tLXQ6XYvNmjUPC/2YXoR6vUHiNERERJ3LLIVlx44dcHV1haOjI95++23s2rUL3t7eN3xvSUkJ9Ho9/Pz8Wjzv5+eHgoKCVr/GsmXLoNFojFtQUJBJj0FuooM94OliD11NA5KzOOstERHZFrMUllGjRkGr1eLgwYO45557MHnyZJNfj7Jo0SKUl5cbt9zcXJPuX26UCoGz3hIRkc0yS2FxcXFBjx49MHToUKxduxYqlQpr16694Xu9vb2hVCpRWNjyh3BhYSH8/f1b/RoODg5Qq9UtNmt3t/H25kJ04NIjIiIii9Mp87AYDAbU1tbe8DV7e3sMGjQISUlJLd6flJSEuLi4zohnMUb28oG9UoGsK9XIKOast0REZDvaXVgqKyuh1Wqh1WoBAJmZmdBqtcjJyUFVVRVefPFF/Pzzz8jOzkZKSgpmzZqFS5cuYdKkScZ9xMfHG+8IAoB58+ZhzZo12LBhA86ePYs//elPqKqqwsyZMzt+hFbE1UGFIWGNs94mcViIiIhsiKq9H0hOTsaoUaOMj+fNmwcASExMxKpVq5CWloYNGzagpKQEXl5eiI2Nxf79+xEREWH8TEZGBkpKSoyPp0yZguLiYixevBgFBQWIiorCzp07f3MhLgF39/XD/vMl2H22EH+8s7vUcYiIiDpFh+ZhkRNrn4elWV5pNUa8sRcKAUj5y93wcLGXOhIREdFtk8U8LGR6XT2cEe7vBoMI7E3nrLdERGQbWFgsUELT3UK8vZmIiGwFC4sFSujbWFj2nStBXQNnvSUiIuvHwmKBBnTRwMfNAZW1DTiceUXqOERERGbHwmKBFAoBv+vduLZQ0llex0JERNaPhcVCxTcthrjrDGe9JSIi68fCYqFG9PSGg0qBS2XXkF5YIXUcIiIis2JhsVDO9ioM79G4AjaHhYiIyNqxsFiw5mEh3t5MRETWjoXFgsWHN97erM0tQ3HFjReXJCIisgYsLBbMX+OI/l00EEVgbxqHhYiIyHqxsFg4DgsREZEtYGGxcM3T9O8/X4Kaer3EaYiIiMyDhcXCRQSq4a92xLV6PQ5lcNZbIiKyTiwsFk4QBA4LERGR1WNhsQLNw0JJZ4s46y0REVklFhYrENfdC052ShToanA6Xyd1HCIiIpNjYbECjnZKjOzZOOsth4WIiMgasbBYieuHhYiIiKwNC4uVGBXuC0EATl4qR0F5jdRxiIiITIqFxUr4uDkgKsgdAJCUxmEhIiKyLiwsVoTDQkREZK1YWKxI83ws/7tQguq6BonTEBERmQ4LixXp7eeGLu5OqG0w4MD5EqnjEBERmQwLixURBAF39+WwEBERWR8WFivTPCyUlFYEg4Gz3hIRkXVgYbEyQ7p5wdVBhZLKWpy4VC51HCIiIpNgYbEy9ioF7ujVNOvtGd7eTERE1oGFxQo1397MafqJiMhasLBYoVG9faEQgLSCCuSVVksdh4iIqMNYWKyQh4s9BoV4AAD2pPFuISIisnwsLFaqeVhoF69jISIiK8DCYqXimwrL4YtXUVnLWW+JiMiysbBYqe4+Lgj1ckad3oD954qljkNERNQhLCxWShAE41mWXbxbiIiILBwLixVrvo7lx/Ri6DnrLRERWTAWFisWE+oBtaMKV6vqcCynVOo4REREt63dhWXfvn0YP348AgMDIQgCtm3bZnytvr4eCxYsQP/+/eHi4oLAwEDMmDED+fn5N93n0qVLIQhCiy08PLzdB0Mt2SkVuKt349pCu7kYIhERWbB2F5aqqipERkZixYoVv3mturoaqampePnll5Gamoovv/wS6enpuO+++26534iICFy+fNm4HThwoL3R6AaaF0PkrLdERGTJVO39wNixYzF27NgbvqbRaLBr164Wzy1fvhyDBw9GTk4OgoODWw+iUsHf37+9cegW7urlC5VCwIWiSmRfqUKIl4vUkYiIiNrN7NewlJeXQxAEuLu73/R958+fR2BgIMLCwjBt2jTk5OTc9P21tbXQ6XQtNvotjbMdYkM9AXBYiIiILJdZC0tNTQ0WLFiAqVOnQq1Wt/q+IUOGYP369di5cydWrlyJzMxMjBw5EhUVFa1+ZtmyZdBoNMYtKCjIHIdgFZqHhZI4LERERBbKbIWlvr4ekydPhiiKWLly5U3fO3bsWEyaNAkDBgzAmDFj8O2336KsrAz//e9/W/3MokWLUF5ebtxyc3NNfQhW4+6+jbc3H8m8ivJr9RKnISIiaj+zFJbmspKdnY1du3bd9OzKjbi7u6NXr164cOFCq+9xcHCAWq1usdGNhXi5oIevKxoMIn7irLdERGSBTF5YmsvK+fPnsXv3bnh5ebV7H5WVlcjIyEBAQICp49ksDgsREZEla3dhqayshFarhVarBQBkZmZCq9UiJycH9fX1ePDBB5GcnIyPP/4Yer0eBQUFKCgoQF1dnXEf8fHxWL58ufHx888/j59++glZWVk4ePAg7r//fiiVSkydOrXjR0gAfpn1dm9aEer1BonTEBERtU+7b2tOTk7GqFGjjI/nzZsHAEhMTMTSpUuxfft2AEBUVFSLz+3duxd33XUXACAjIwMlJSXG1/Ly8jB16lRcuXIFPj4+GDFiBH7++Wf4+Pi0Nx61YmCwBzyc7VBaXY/krFLEdW//mS8iIiKptLuw3HXXXRDF1teludlrzbKyslo8/vTTT9sbg9pJqRAwKtwXX6ZeQtLZQhYWIiKyKFxLyIY0DwvtPlvYpmJJREQkFywsNmRkT2/YKQVkXalGRnGV1HGIiIjajIXFhrg52mFoWONQEO8WIiIiS8LCYmOah4WSOE0/ERFZEBYWG9M8H0ty9lWUVtXd4t1ERETywMJiY7p6OCPc3w0GEdibzrMsRERkGVhYbBCHhYiIyNKwsNig5mGhn84Vo66Bs94SEZH8sbDYoMiu7vB2dUBlbQOOZF6VOg4REdEtsbDYIIVCQHx441mW3by9mYiILAALi41qHhbirLdERGQJWFhs1Iie3rBXKZBXeg3nCiuljkNERHRTLCw2ytleheFNCyByWIiIiOSOhcWGJfT9ZTFEIiIiOWNhsWHx4Y2FRZtbhpLKWonTEBERtY6FxYb5axzRr4saogh8d6pA6jhEREStYmGxceP6BwIAln17FifzyiVOQ0REdGMsLDZu9ohuGNnTG9V1esxcfxS5V6uljkRERPQbLCw2zl6lwHvTBqJPgBollbVIXHeEqzgTEZHssLAQ3BztsO7RWARoHHGxuAqPbUxGTb1e6lhERERGLCwEoPEC3PUzB8PNUYXk7FLM+68WBgNnwCUiInlgYSGj3v5ueH/6INgpBXx7sgCvfXtW6khEREQAWFjoV4Z198abkyIBAGsPZOLDA5kSJyIiImJhoRuYENUFC+4JBwC88s0ZfHfyssSJiIjI1rGw0A09cWcYHhkaDFEEnvlMi+Ssq1JHIiIiG8bCQjckCAKWjo9AQh9f1DUYMGdjMjKKuaozERFJg4WFWqVSKvDu1GhEBrmjrLoej647guIKrjlERHS9K5W1+NvXZ3Awo0TqKFaNhYVuytlehbWJMQj2dEbu1WuYveEoqusapI5FRCQLNfV6PLYxGR/+LxMz1x3FibwyqSNZLRYWuiVvVwdsmDUYHs52OJFXjic/OYYGvUHqWEREkhJFES98cQKpOWUAgNoGAx7bmIyC8hppg1kpFhZqk27eLvggMRYOKgX2pBXh5a9OQxQ5sRwR2a5/J53H9uP5UCkErJ4+CD19XVGoq8Xjm5JxrY6zhZsaCwu12aAQD/z7oWgIArD5SA7e+zFD6khERJL4SnsJ7+w+DwB47f5+GB3hj7WJscYz0fO/OM5f6kyMhYXa5Z5+/ljy+74AgH9+n44vU/MkTkRE1LlSsksx/4sTAIA/3hGGKbHBAIBgL2esfGQQVAoBO05cxn/2XJAyptVhYaF2e3R4Nzx+RxgA4IUvTuB/F3hlPBHZhtyr1fjjpmTUNRhwd18/vNA0yWazoWFeeGViPwDAW7vOceJNE2Jhoduy8J5w/H5AABoMIp7YlIK0Ap3UkYiIzKqiph5zNiSjpLIOEYFq/PuhKCgVwm/eN3VwMGYODwUAzPvvcZy6VN7JSa0TCwvdFoVCwJuTIjG4mycqahvw6IdHcbn8mtSxiIjMokFvwJOfHEN6YQX81A74IDEGzvaqVt//0r19cEcvH1xruu25SMc7hzqKhYVum6OdEmumx6CHrysKdDV49MOj0NXUSx2LiMjkXv3mLH46VwxHOwU+mBGLAI3TTd+vUirwn6nRCPNxweXyGjy+KQU19bxzqCNYWKhDNM52WD8zFj5uDkgvrMCfPkpBXQPnaCEi67HxUBbWH8wCALwzJQr9u2ra9DmNkx3WJsZC42QHbW4ZFm45wTuHOqDdhWXfvn0YP348AgMDIQgCtm3bZnytvr4eCxYsQP/+/eHi4oLAwEDMmDED+fn5t9zvihUrEBoaCkdHRwwZMgRHjhxpbzSSSFcPZ6x7NBYu9kr878IVLOA/SiKyEj+mF2Hp9tMAgAX3hOOefgHt+nw3bxesnDYQSoWAbdp8TgfRAe0uLFVVVYiMjMSKFSt+81p1dTVSU1Px8ssvIzU1FV9++SXS09Nx33333XSfn332GebNm4clS5YgNTUVkZGRGDNmDIqKitobjyTSr4sG7z0yCEqFgK3HLuHNH9KljkRE1CHnCivw1CfHYBCBSYO64ok7w25rP8N6eGPpfREAGqeD+OF0gSlj2gxB7MCvwoIgYOvWrZg4cWKr7zl69CgGDx6M7OxsBAcH3/A9Q4YMQWxsLJYvXw4AMBgMCAoKwlNPPYWFCxe2KYtOp4NGo0F5eTnUanW7j4VM479Hc/HClsb5Cf5+f388POTG/8+JiOSspLIWE1f8D3ml1zCkmyc2zR4Ce1XHrqJY/NUpbDyUDWd7Jb54Yhj6BvJnFdD2n99mv4alvLwcgiDA3d39hq/X1dUhJSUFCQkJv4RSKJCQkIBDhw61ut/a2lrodLoWG0lvcmwQnonvCQD4y7aTSDpbKHEiIqL2qanX4/GNycgrvYZQL2esemRQh8sKALz8+74Y3sML1XWNdw6VVNaaIK3tMGthqampwYIFCzB16tRWW1NJSQn0ej38/PxaPO/n54eCgtZPmy1btgwajca4BQUFmTQ73b5nE3pi0qCuMIjAk58cw/HcMqkjERG1yfULGqodVVj7aCw8XOxNsm87pQLvPTwI3bxdcKnsGp7YlILaBt451FZmKyz19fWYPHkyRFHEypUrTb7/RYsWoby83Ljl5uaa/GvQ7REEAX9/oD9G9vTGtXo9Zm84ipwr1VLHIiK6pXeTLhgXNFz1yCB093E16f41znZYMyMGbo4qJGeX4sUvT/EmhTYyS2FpLivZ2dnYtWvXTcekvL29oVQqUVjYcuigsLAQ/v7+rX7OwcEBarW6xUbyYadU4L1pA9E3QI2Syjo8uu4ISqvqpI5FRNSq7cfz8fbucwCAVyf2w7Ae3mb5Oj18XbHi4cY7h7ak5mHN/otm+TrWxuSFpbmsnD9/Hrt374aXl9dN329vb49BgwYhKSnJ+JzBYEBSUhLi4uJMHY86kZujHdbNjEUXdydcLKnCnI3JnDiJiGQpNacUz39+HADw+B1heGiweW8YuKOXD14e1wcAsOy7NF7v1wbtLiyVlZXQarXQarUAgMzMTGi1WuTk5KC+vh4PPvggkpOT8fHHH0Ov16OgoAAFBQWoq/vlt+v4+HjjHUEAMG/ePKxZswYbNmzA2bNn8ac//QlVVVWYOXNmx4+QJOWndsS6mbFwc1QhJbsUz36qhd7A059EJB+5V6vx+MZfFjRc8KsFDc0lcVgopg4OhigCT28+hvSCik75upaq3YUlOTkZ0dHRiI6OBtBYNqKjo7F48WJcunQJ27dvR15eHqKiohAQEGDcDh48aNxHRkYGSkp+WeF3ypQpePPNN7F48WJERUVBq9Vi586dv7kQlyxTLz83rJ4eA3ulAjtPF+DVb85IHYmICEDLBQ37BqjxzpQbL2hoDoIg4G8TIjA0zBNVdY3X+13hnUOt6tA8LHLCeVjkb/vxfDy9+RgA4C/j+mDOyNubhImIyBQa9AbM2ZiMH9OL4evmgK+eHH7LNYLMobSqDhNW/A85V6sxuJsnPjLBnC+WRDbzsBA1uy8yEAvHNp5qfe3bs/jmxGWJExGRLXv1m7P4Mb1xQcO1ibde0NBcPFzssTYxBm4OKhzJvIqXt/HOoRthYaFO9cc7wjAjLgSiCDz3Xy2OZl2VOhIR2aDbXdDQXHr6ueHdh6OhEIDPknPx4f+yJM0jRyws1KkEQcCS8RG4u68f6hoMmLMhGReKKqWORUQ25Kdzxfjr143X0t3OgobmMqq3L168t/HOode+OYO96VxP73osLNTplAoB7z4Ujaggd5Rfq8ej646gqKJG6lhEZAPOFVbgyY9ToTeIHVrQ0Fxmj+iGyTGNM4U//ckxXCjinUPNWFhIEk72SqxNjEGolzPySq9h1vqjqKptkDoWEVmxkspazFp/FBW1DRjczROv3d8fgtA5dwS1lSAIeHVifwwO9URFbQNmb0jmpJtNWFhIMl6uDlg/czA8Xexx6pIOT36Siga9QepYRGSFfr2g4fsmWtDQHOxVCqx8ZCC6ejgh+0o1/u/jVNTzeyMLC0kr1NsFHyTGwNFOgb3pxXj5K14dT0SmJYoiFmwxz4KG5uLl6oAPEmPgYq/EoYtXsHT7aZv/3sjCQpIbGOyBdx9qvDp+85FcLN9zQepIRGRF3k26gK+05lvQ0FzC/dX490PREATg48M52HgoW+pIkmJhIVkYHeGPpfdFAAD+tesctqTkSZyIiKxBZy1oaC4J1y0V8LcdZ7D/fLHEiaTDwkKyMSMuFH9sumJ/wZYTNv0Pk4g6rrMXNDSXP94RhgcGdoHeIGLux6m4WGybU0GwsJCsLBgTjvGRgWgwiPjTR6k4k6+TOhIRWaDrFzRM6NN5CxqagyAI+Pv9/TEw2B26mgbM2ZCM8up6qWN1OhYWkhWFQsCbkwZgSDdPVNY2YOb6I8gvuyZ1LCKyIL9e0PDfD3Xegobm4minxPvTY9DF3QkXS6ow1wbvqmRhIdlxUCmxenoMevq6olBXi0fXHUH5Ndv7bYKI2q9Bb8BTm48hvbACvm4OWPtoDFwcVFLHMgkfNwesmREDJzslDlwowSs7zkgdqVOxsJAsaZztsH7WYPi6OeBcYSWe2JSC2ga91LGISOauX9Dwg8QYyRY0NJe+gWq8PSUKALDhUDY++tl27hxiYSHZ6uLuhHUzY43zECz44gQMBtueh4CIWrfpVwsaDujqLmkec7mnnz/mj+kNAFi6/TQOZpRInKhzsLCQrEUEarDykUFQKQRs0+bjnz+kSx2JiGTop3PFWNq0oOEL9/SWzYKG5vJ/d3XHhKhfblDIKqmSOpLZsbCQ7N3RywfLHugPAFj5Y4ZNnQIlolu7fkHDBwd1xZ/u7C51JLMTBAFv/GEAIpsWkZ294Sh0NdZ9rR8LC1mESTFBeDahJwBg8VensPtMocSJiEgOfr2g4d9luKChuTjaKbFm+iD4qx2RUVyFpz45ZtV3DrGwkMV4Jr6ncdn1JzenQptbJnUkIpJQTb0ef9yUgrzSawiR+YKG5uKrdjSux/bTuWIs+y5N6khmY1v/Z8miCYKA1+7vjzt6+aCm3oDZ648i+4r1j9sS0W81L2iYkl0KtaMKH1rAgobm0q+LBm9NjgIArD2Qic+O5kgbyExYWMii2CkVeG/aQEQEqnGlqg6PrjuKq1V1Usciok52/YKGKy1oQUNzubd/AJ5L6AUA+Mu2Uzh88YrEiUyPhYUsjquDCusejUUXdydkllRhzoajqKnnHC1EtuL6BQ1fmdgPwy1sQUNzeTq+B8YNCEC9XsQTH6Ug92q11JFMioWFLJKv2hEbZsVC7ahCak4Znvn0GPSco4XI6l2/oOFjI7thqoUuaGgOgiDgzQcj0b+LBqXVjXcOVVjRnUMsLGSxevi6Yc2MGNgrFfj+dCFe2XEGosjSQmSt8kpbLmi4cGwfqSPJjpO9EmtmxBhnCX/mU63V/DLHwkIWbUiYF/41ORIAsP5gFj7YnylxIiIyh4qaesxeb10LGpqLv8YRa2bEwEGlwJ60Ivxjp3XcOcTCQhZvfGQgXry3cen41749ix0n8iVORESmZM0LGppLZJA7/jmp8Ze59/ddxOfJuRIn6jgWFrIKj40MQ2JcCABg3mfHrfIKeSJbZe0LGprLfZGBeOp3PQAAL209heSsqxIn6hgWFrIKgiBg8fgIjO7rhzq9AY9tTMaFogqpYxFRB12/oOHbk613QUNzeS6hF8b280ed3tA0yZ7l3jnEwkJWQ6kQ8O7UaEQHu0NX04DED4+iSFcjdSwiuk3XL2g4f0xvjO1v3QsamoNCIeBfkyPRN6Bx7qo5G5JRVdsgdazbwsJCVsXRTom1ibHo5u2CS2XXMHP9UVRa6D9OIlt2/YKGfxjYFf93l/UvaGguzvYqfJAYA29XB6QVVODZz7QwWOCdQywsZHU8XeyxfmYsvFzscTpfh7kfp6LeihcEI7I2V361oOGyB2xnQUNzCXR3wuoZjWst7TpTiDd/SJc6UruxsJBVCvFywdpHY40Lgi3ZflrqSETUBjX1ejx+3YKGq2xwQUNzGRjsgTf+0B8A8N6PGdh27JLEidqHfwvIakUFueM/UwdCEIBPDudgT1qh1JGI6CZ+vaDh2sRYeNrogobmcn90V/ypaXjthS0ncCynVOJEbcfCQlbt7r5+mDOiGwBg0ZcnUX7NeqapJrI2/9nTckHDHr62vaChucwf3Rt39/VDXYMBj21MQX7ZNakjtQkLC1m9P4/ujW7eLijU1eLVHWekjkNEN/D18Xy8tYsLGnYGhULA21OiEO7vhpLKWjy2MRnVdfK/OYGFhayeo50S/3hwAAQB+DwlDz+mF0kdiYiuk5pTij9zQcNO5erQeOdQ880Jf/7vcdnfOcTCQjYhNtQTiXGhABqHhqxpBVMiS8YFDaXT1cMZ708fBDulgO9OFeCd3eekjnRT7S4s+/btw/jx4xEYGAhBELBt27YWr3/55ZcYPXo0vLy8IAgCtFrtLfe5fv16CILQYnN0dGxvNKKbeuGe3gj2dMbl8hr8/VvrWAyMyJJdv6BhHy5oKImYUE/8/f7GO4fe3XMBXx+X71ps7S4sVVVViIyMxIoVK1p9fcSIEXjjjTfatV+1Wo3Lly8bt+zs7PZGI7opZ3sV3vjDAADA5iM5OHC+ROJERLarQW/A09cvaJjIBQ2lMikmCI/fEQYAeP7z4zieWyZtoFa0+2/H2LFjMXbs2FZfnz59OgAgKyurXfsVBAH+/v7tjUPULnHdvTB9aAg2/ZyNBVtO4Pvn7oArv0kSdbpXvzmLvdctaBjozgUNpbTgnnBcKKrEnrQiPLYxGdufHAF/jbxGOmRzDUtlZSVCQkIQFBSECRMm4PTpm0/0VVtbC51O12IjaouFY8PR1cMJl8qu4Y3vODRE1NmuX9DwLS5oKAtKhYB/PxSFXn6uKKqoxeObknGtTi91rBZkUVh69+6NDz/8EF999RU++ugjGAwGDBs2DHl5ea1+ZtmyZdBoNMYtKCioExOTJXNx+GVoaNPP2TiUcUXiRES249cLGt7LBQ1lw83RDh/MiIWHsx1O5JVj/hfHIYryuXNIFoUlLi4OM2bMQFRUFO688058+eWX8PHxwfvvv9/qZxYtWoTy8nLjlpub24mJydIN7+FtvHVywZYTFjEHAZGlO88FDWUv2MsZKx8ZBJVCwI4Tl/GfPRekjmQki8Lya3Z2doiOjsaFC63/QTk4OECtVrfYiNrjxXvDEahxRM7Vavxjp+UtBEZkSa5U1mLWhqYFDUM98fcH+nFBQ5kaGuaFVyf2AwC8tescvjt5WeJEjWRZWPR6PU6ePImAAJ4qJPNxc7TDsqahoQ2HsnAk86rEiYisU/OChrlXmxY0nD4IDiql1LHoJh4aHIyZw0MBAM/9V4tTl8qlDYTbKCyVlZXQarXG+VUyMzOh1WqRk5MDALh69Sq0Wi3OnGkco0xPT4dWq0VBQYFxHzNmzMCiRYuMj//2t7/hhx9+wMWLF5GamopHHnkE2dnZmDNnTkeOjeiW7uzlg8kxXSGKwAtfHJfdRWZElk5vEPH858e5oKEFeunePrijlw9q6g14bGMyinQ1kuZpd2FJTk5GdHQ0oqOjAQDz5s1DdHQ0Fi9eDADYvn07oqOjMW7cOADAQw89hOjoaKxatcq4j5ycHFy+/MspptLSUjz22GPo06cP7r33Xuh0Ohw8eBB9+/bt0MERtcVL4/rCT+2ArCvV+NcPHBoiMhVRFPGXbSex48Rl2Cm5oKGlUSkVWP5wNLr7uOByeQ0e35SCmnrpfqkTRDldAtwBOp0OGo0G5eXlvJ6F2m1PWiFmrU+GIABfPDEMg0I8pI5EZNFEUcSy79Kwet9FKATgP1MHYtwADvNbosySKkxc8T9cq9Nj0+zBGBLmZdL9t/XntyyvYSHqbL8L98MDA7tAFIH5XxyX9LcIImuwYu8FrN53EQDw+gMDWFYsWDdvF6x6ZBA2Pz7U5GWlPVhYiJos/n1f+Lg54GJxFd6W+SJgRHK24WAW3vyh8d/QX8b1weRYzpNl6eK6e0l+5pmFhaiJu7M9Xmu6lW/NvovQynQ9DSI525KShyXbG2cqfya+J+aMDJM4EVkLFhai64yO8MeEqEAYRGD+58dR28ChIaK22nmqAPO/OA4AmDk8FM8m9JQ4EVkTFhaiX1k6PgLervY4X1SJ/yTJZ5ZHIjnbf74YT28+BoMITBrUFS+P68uJ4cikWFiIfsXDxR6vTGgcGlr5UwZO5kk/YRKRnKVkl+LxjSmo0xswtp8/lj3QHwoFywqZFgsL0Q2M7R+Acf0DoDeImP/FcdQ1GKSORCRLZ/J1mLnuCK7V63FHLx+881AUVEr+aCHT498qolb8dUIEPF3skVZQgRV7OTRE9GsXiysx48PD0NU0ICbEA6seGcgp98lsWFiIWuHt6oC/3hcBoHFOiTP5OokTEcnHpbJreOSDwyiprENEoBofzoyFs71K6lhkxVhYiG7i9wMCMCbCDw1N66HU6zk0RFRcUYvpHxxGfnkNwnxcsGHWYKgd7aSORVaOhYXoJgRBwCsT+8Hd2Q5nLuuw6scMqSMRSaq8uh4zPjyCiyVV6OLuhI/nDIG3q4PUscgGsLAQ3YKvmyOWjm8cGnp3z3mkF1RInIhIGtV1DZi5/gjOXtbB29UBH80ZggCNk9SxyEawsBC1wYSoQCT08UW9vnFoqIFDQ2Rjahv0+OOmFKTmlEHtqMKm2YPRzdtF6lhkQ1hYiNpAEAS8dn9/qB1VOHmpHKv3X5Q6ElGnadAb8PTmY9h/vgTO9kqsnzUYfQJaX1WXyBxYWIjayE/tiMVNQ0Pv7DqPC0UcGiLrZzCIWLDlJL4/XQh7pQJrZsRgYLC0i+CRbWJhIWqHPwzsgrt6+6BOb8Dzn5+A3iBKHYnIbERRxN92nMGW1DwoFQKWPxyN4T28pY5FNoqFhagdBEHAsgf6w81BBW1uGdYe4NAQWa+3d53D+oNZAIA3Jw3A6Ah/aQORTWNhIWqnAI0TXhrXBwDwrx/O4WJxpcSJiExvzb6LeHdP4wzPr0yIwP3RXSVORLaOhYXoNkyJDcLInt6obTDghS84NETWZfORHLz27VkAwPwxvTE9LlTaQERgYSG6LYIg4PU/DICLvRLJ2aXY0HTanMjSfX08Hy9uPQkAeOLO7pg7qofEiYgasbAQ3aYu7k5YdG/j0NA/vk9DVkmVxImIOmZvWhGe+0wLUQSmDQnGgnt6Sx2JyIiFhagDHh4cjGHdvVBTb8ALW07AwKEhslA/X7yCJz5KQYNBxISoQLwyoR8EQZA6FpERCwtRBygUAt74wwA42ytxJPMqPjqcLXUkonY7kVeGORuSUdtgQEIfX7w5KRIKBcsKyQsLC1EHBXk6Y8E94QCA179LQ+7VaokTEbXd+cIKJH54BJW1DYgL88LyhwfCTskfDSQ//FtJZALTh4ZgcDdPVNfpsWDLCYgih4ZI/nKuVGPaB4dRWl2PyCB3rEmMgaOdUupYRDfEwkJkAgqFgH/8YQAc7RQ4mHEFnxzJkToS0U0V6mrwyNrDKKqoRW8/N2yYGQtXB5XUsYhaxcJCZCKh3i6YP6ZxaOjv35xFXimHhkieSqvq8MgHh5FztRohXs7YNHsw3J3tpY5FdFMsLEQm9OiwUAwK8UBVnR6LvjzJoSGSnYqaeiSuO4LzRZXwVzvio9lD4Kt2lDoW0S2xsBCZkFIh4B8PDoCDSoH950vw3+RcqSMRGdXU6zFnQzJO5JXD08UeH80ZjCBPZ6ljEbUJCwuRiXX3ccWfR/cCALy64ywul1+TOBERUNdgwP99nIrDmVfh5qDCxlmD0cPXTepYRG3GwkJkBrNHhCEqyB0VtQ14kUNDJDG9QcS8/2qxJ60IDioF1j4ai35dNFLHImoXFhYiM1AqBPzzwQGwVyqwN70YW1IvSR2JbJQoivjLtlPYceIy7JQCVk0fhMHdPKWORdRuLCxEZtLTzw3P3t0TAPC3r0+jUFcjcSKyNaIo4vXv0rD5SA4UAvDOlGiM6u0rdSyi28LCQmRGj48Mw4CuGuhqGvDS1lMcGqJO9d6PGXh/30UAwLIH+mPcgACJExHdPhYWIjNSKRX454ORsFMK2H22ENuP50sdiWzEhoNZ+Of36QCAv4zrgymxwRInIuoYFhYiM+vt74anftc4NLRk+2kUVXBoiMxrS0oelmw/DQB4Or4n5owMkzgRUcexsBB1gj/d1R19A9Qoq67H4m2nOTREZrPzVAFe2HICADBzeCieS+gpcSIi02h3Ydm3bx/Gjx+PwMBACIKAbdu2tXj9yy+/xOjRo+Hl5QVBEKDVatu0388//xzh4eFwdHRE//798e2337Y3GpFs2SkVeHNSJFQKATtPF+Cbk5eljkRW6MD5Ejy9+Rj0BhEPDuqKl8f1hSAIUsciMol2F5aqqipERkZixYoVrb4+YsQIvPHGG23e58GDBzF16lTMnj0bx44dw8SJEzFx4kScOnWqvfGIZKtvoBr/N6oHAGDxV6dxpbJW4kRkTVKyS/HYxmTU6Q0Y288frz/QHwoFywpZD0HswLlpQRCwdetWTJw48TevZWVloVu3bjh27BiioqJuup8pU6agqqoKO3bsMD43dOhQREVFYdWqVW3KotPpoNFoUF5eDrVa3Z7DIOo0dQ0G3Lf8ANIKKjBuQABWPDxQ6khkBc7k6/DQ6kPQ1TRgZE9vfJAYAweVUupYRG3S1p/fsriG5dChQ0hISGjx3JgxY3Do0CGJEhGZh72qcWhIqRDwzYnL2HmKQ0PUMReLKzHjw8PQ1TQgJsQD708fxLJCVkkWhaWgoAB+fn4tnvPz80NBQUGrn6mtrYVOp2uxEVmCfl00eOLOxrs2/rLtFEqr6iRORJbqUtk1PPLBYZRU1qFvgBprH42Fs71K6lhEZiGLwnI7li1bBo1GY9yCgoKkjkTUZk/H90RPX1eUVNZh6denpY5DFqi4ohbTPziM/PIahPm4YOPswdA42Ukdi8hsZFFY/P39UVhY2OK5wsJC+Pv7t/qZRYsWoby83Ljl5uaaOyaRyTiolPjnpEgoBOArbT52nSm89YeImpRfq8eMD4/gYkkVurg74aPZQ+Dt6iB1LCKzkkVhiYuLQ1JSUovndu3ahbi4uFY/4+DgALVa3WIjsiRRQe547I7GoaGXtp5EeXW9xInIElTXNWDW+qM4e1kHb1cHfDRnCALdnaSORWR27S4slZWV0Gq1xvlVMjMzodVqkZOTAwC4evUqtFotzpw5AwBIT0+HVqttcT3KjBkzsGjRIuPjZ555Bjt37sS//vUvpKWlYenSpUhOTsaTTz7ZkWMjkr3nEnohzMcFRRW1+NuOM1LHIZmrbdDjj5tSkJJdCrWjCptmD0Y3bxepYxF1inYXluTkZERHRyM6OhoAMG/ePERHR2Px4sUAgO3btyM6Ohrjxo0DADz00EOIjo5ucXtyTk4OLl/+5e6IYcOG4ZNPPsHq1asRGRmJL774Atu2bUO/fv06dHBEcudop8Q/H4yEIABbUvOwJ41DQ3RjDXoDnt58DPvPl8DZXon1swajTwDPLJPt6NA8LHLCeVjIkr264ww+OJAJf7Ujfph3B9SOvHiSfmEwiJj/xQlsSc2DvVKBdTNjMbyHt9SxiEzCouZhIbJ1fx7dG6FezijQ1eC1HWeljkMyIooi/rbjDLak5kGpELD84WiWFbJJLCxEMuBkr8Q/moaGPkvOxb5zxVJHIpl4e9c5rD+YBQB4c9IAjI5o/e5JImvGwkIkE4O7eSIxLhQAsHDLCVTU8K4hW7dm30W8u+cCAOCVCRG4P7qrxImIpMPCQiQjL9zTG8Gezsgvr8Gy79KkjkMS+vRIDl77tnF4cP6Y3pjeVGaJbBULC5GMONur8MYfBgAAPjmcg/9dKJE4EUnh6+P5WLT1JADgj3eG4f/u6i5xIiLpsbAQyUxcdy88MjQYALBgywlU1TZInIg60960Ijz3mRaiCDw8JBgL7wmHIAhSxyKSHAsLkQwtHNsHXdydkFd6DW/s5NCQrTh88Qqe+CgFDQYRE6IC8cqEfiwrRE24rCeRDLk6NA4NPbL2MDYeysa9/QMwNMxL6lidrkhXg+TsUpy6VA6DCNirFHBQKWCnFGCvVMBepYR902MHlQL2KgXslcrG15seN76/+TWF8Xl7pUJWZeBEXhlmb0hGbYMB8eG+eHNSJJQK+eQjkhoLC5FMjejpjamDg7D5SC4WbDmB754ZCWd76/0nazCIOFdUgeSsUqRklyI5+ypyr14z69f8pfhcV2quLzbXPdf8usMNnrvR++2VCtg1/dfhFu8vqqhB4odHUFnbgLgwL6yYNhB2Sp4AJ7qe9X73I7ICL97bBz+lFyP7SjX++X06loyPkDqSyVTXNUCbW4aUrFIkZ5ciNacUFTUtr9cRBKC3nxuigz3gZKdEnV6PugYD6vUi6hoMqG0woE5vQH3Tf+saDE2v//Ja8+O6BgMaDC0n9q7Xi6jX61FVp+/MQ29VZFcN1iTGwNFOKXUUItlhYSGSMTdHOyz7wwAkfngE6w9mYVz/AMSEekod67YU6mqQnNV45iQluxSn83XQ/6pAONsrERXkjpgQDwwK9UR0sLtJlykwGMTGEnNdublZwam7vgjd4LVavQH1DaKxSDWXqV/2pTeWq5vtq8EgYnCoJ96fPgiuDvy2THQj/JdBJHN39vLBpEFd8XlKHl744gS+fWak7H8D1xtEnCusQHJ2KVKyriI5uxR5pb8d3gnQOGJQiAcGhXggJsQTfQLcoDLjUIhCIcBRoZTdn5/BIELB61WIboqFhcgC/OX3fbHvfDEullThrV3n8OK9faSO1EJVbePwTnJWKVJySnEsuxQVv7odWyEA4f5qxIQ2FZRQT3Rxd5IosbywrBDdGgsLkQXQONlh2QP9MWt9Mj7YfxH39PPHwGAPyfJcLr/W4uLYs5crfjO842KvRHRwcznxQFSQO9y4CjUR3SYWFiIL8btwPzwQ3QVfHruE+Z8fxzdPd87QkN4gIq1A11hOmkrKpbLfDu8EahwxKNSz8fqTEA+E+5t3eIeIbAsLC5EFWTy+L/ZfKEFGcRX+nXQeC+4JN/nXqKxtgDanzHhx7LGcMlTeYHinT4DaeHFsTIgHAjm8Q0RmxMJCZEHcne3x2sR+eHxTCt7/KQP3RPgjMsi9Q/vML7vW4uLYs5d1+NXoDlwdVIgOdjdeHBsV7M67WYioU/E7DpGFGR3hj/siA7H9eD7mf3EcXz81Ag6qtg0N6Q0izl5uGt5pKin55TW/eV8XdyfjtSeNwztqzrpKRJJiYSGyQEvvi8DBjBKcK6zE8j0X8OfRvW/4vsraBhzL+eXak2M5pb+ZJE2pENAnwA0xIZ7GkhKg4fAOEckLCwuRBfJ0scffJvTD/32civd+zMCYCH/066LBpbJrSM66arxANq3gt8M7bg4qRId4GC+OjQpyhwuHd4hI5vhdishC3ds/AOP6B+Cbk5cxe8NRKAQBl28wvNPVw6nFxbG9/Nw4vENEFoeFhciC/XVCBA5dvIJCXS2AxuGdiEC18eLYmFAP+KkdJU5JRNRxLCxEFszb1QEbZw3GwYwS9OuiQVSQu1Wv6ExEtovf2YgsXL8uGvTropE6BhGRWXEaSiIiIpI9FhYiIiKSPRYWIiIikj0WFiIiIpI9FhYiIiKSPRYWIiIikj0WFiIiIpI9FhYiIiKSPRYWIiIikj0WFiIiIpI9FhYiIiKSPRYWIiIikj0WFiIiIpI9q1mtWRRFAIBOp5M4CREREbVV88/t5p/jrbGawlJRUQEACAoKkjgJERERtVdFRQU0Gk2rrwvirSqNhTAYDMjPz4ebmxsEQTDZfnU6HYKCgpCbmwu1Wm2y/cqJtR8jj8/yWfsx8vgsn7UfozmPTxRFVFRUIDAwEApF61eqWM0ZFoVCga5du5pt/2q12ir/El7P2o+Rx2f5rP0YeXyWz9qP0VzHd7MzK8140S0RERHJHgsLERERyR4Lyy04ODhgyZIlcHBwkDqK2Vj7MfL4LJ+1HyOPz/JZ+zHK4fis5qJbIiIisl48w0JERESyx8JCREREssfCQkRERLLHwkJERESyx8LSin379mH8+PEIDAyEIAjYtm2b1JFMatmyZYiNjYWbmxt8fX0xceJEpKenSx3LpFauXIkBAwYYJzqKi4vDd999J3Uss3n99dchCAKeffZZqaOYxNKlSyEIQostPDxc6lgmd+nSJTzyyCPw8vKCk5MT+vfvj+TkZKljmURoaOhv/h8KgoC5c+dKHc0k9Ho9Xn75ZXTr1g1OTk7o3r07XnnllVuuiWNJKioq8OyzzyIkJAROTk4YNmwYjh49KkkWq5np1tSqqqoQGRmJWbNm4YEHHpA6jsn99NNPmDt3LmJjY9HQ0IAXX3wRo0ePxpkzZ+Di4iJ1PJPo2rUrXn/9dfTs2ROiKGLDhg2YMGECjh07hoiICKnjmdTRo0fx/vvvY8CAAVJHMamIiAjs3r3b+Filsq5vWaWlpRg+fDhGjRqF7777Dj4+Pjh//jw8PDykjmYSR48ehV6vNz4+deoU7r77bkyaNEnCVKbzxhtvYOXKldiwYQMiIiKQnJyMmTNnQqPR4Omnn5Y6nknMmTMHp06dwqZNmxAYGIiPPvoICQkJOHPmDLp06dK5YUS6JQDi1q1bpY5hVkVFRSIA8aeffpI6ill5eHiIH3zwgdQxTKqiokLs2bOnuGvXLvHOO+8Un3nmGakjmcSSJUvEyMhIqWOY1YIFC8QRI0ZIHaPTPPPMM2L37t1Fg8EgdRSTGDdunDhr1qwWzz3wwAPitGnTJEpkWtXV1aJSqRR37NjR4vmBAweKL730Uqfn4ZAQAQDKy8sBAJ6enhInMQ+9Xo9PP/0UVVVViIuLkzqOSc2dOxfjxo1DQkKC1FFM7vz58wgMDERYWBimTZuGnJwcqSOZ1Pbt2xETE4NJkybB19cX0dHRWLNmjdSxzKKurg4fffQRZs2aZdIFaqU0bNgwJCUl4dy5cwCA48eP48CBAxg7dqzEyUyjoaEBer0ejo6OLZ53cnLCgQMHOj2PdZ1fpdtiMBjw7LPPYvjw4ejXr5/UcUzq5MmTiIuLQ01NDVxdXbF161b07dtX6lgm8+mnnyI1NVWyMWVzGjJkCNavX4/evXvj8uXL+Otf/4qRI0fi1KlTcHNzkzqeSVy8eBErV67EvHnz8OKLL+Lo0aN4+umnYW9vj8TERKnjmdS2bdtQVlaGRx99VOooJrNw4ULodDqEh4dDqVRCr9fjtddew7Rp06SOZhJubm6Ii4vDK6+8gj59+sDPzw+bN2/GoUOH0KNHj84P1OnndCwQrHxI6IknnhBDQkLE3NxcqaOYXG1trXj+/HkxOTlZXLhwoejt7S2ePn1a6lgmkZOTI/r6+orHjx83PmdNQ0K/VlpaKqrVaqsa0rOzsxPj4uJaPPfUU0+JQ4cOlSiR+YwePVr8/e9/L3UMk9q8ebPYtWtXcfPmzeKJEyfEjRs3ip6enuL69euljmYyFy5cEO+44w4RgKhUKsXY2Fhx2rRpYnh4eKdnYWFpA2suLHPnzhW7du0qXrx4UeoonSI+Pl58/PHHpY5hElu3bjV+E2neAIiCIIhKpVJsaGiQOqLJxcTEiAsXLpQ6hskEBweLs2fPbvHce++9JwYGBkqUyDyysrJEhUIhbtu2TeooJtW1a1dx+fLlLZ575ZVXxN69e0uUyHwqKyvF/Px8URRFcfLkyeK9997b6Rl4DYuNEkURTz75JLZu3Yo9e/agW7duUkfqFAaDAbW1tVLHMIn4+HicPHkSWq3WuMXExGDatGnQarVQKpVSRzSpyspKZGRkICAgQOooJjN8+PDfTCdw7tw5hISESJTIPNatWwdfX1+MGzdO6igmVV1dDYWi5Y9RpVIJg8EgUSLzcXFxQUBAAEpLS/H9999jwoQJnZ6B17C0orKyEhcuXDA+zszMhFarhaenJ4KDgyVMZhpz587FJ598gq+++gpubm4oKCgAAGg0Gjg5OUmczjQWLVqEsWPHIjg4GBUVFfjkk0/w448/4vvvv5c6mkm4ubn95pojFxcXeHl5WcW1SM8//zzGjx+PkJAQ5OfnY8mSJVAqlZg6darU0Uzmueeew7Bhw/D3v/8dkydPxpEjR7B69WqsXr1a6mgmYzAYsG7dOiQmJlrdbenjx4/Ha6+9huDgYERERODYsWN46623MGvWLKmjmcz3338PURTRu3dvXLhwAfPnz0d4eDhmzpzZ+WE6/ZyOhdi7d68I4DdbYmKi1NFM4kbHBkBct26d1NFMZtasWWJISIhob28v+vj4iPHx8eIPP/wgdSyzsqZrWKZMmSIGBASI9vb2YpcuXcQpU6aIFy5ckDqWyX399ddiv379RAcHBzE8PFxcvXq11JFM6vvvvxcBiOnp6VJHMTmdTic+88wzYnBwsOjo6CiGhYWJL730klhbWyt1NJP57LPPxLCwMNHe3l709/cX586dK5aVlUmSRRBFK5qSj4iIiKwSr2EhIiIi2WNhISIiItljYSEiIiLZY2EhIiIi2WNhISIiItljYSEiIiLZY2EhIiIi2WNhISIiItljYSEiIiLZY2EhIiIi2WNhISIiItljYSEiIiLZ+3+60nyfiX/UZwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Entrenamiento\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que la perplexity del modelo no aumenta demasiado una vez se detiene el entrenamiento, por lo que decidimos quedarnos con la epoca 9 a pesar de que hay otras con mejor perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('char_my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede comprobar en el \"tester\" del modelo su capacidad para completar palabras correctamente, pero una vez pasa a la siguiente palabra tiende a entrar en bucle en poco tiempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the key to success to the in the surved to re'"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='the key to succ'\n",
        "\n",
        "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you have received your program wit.\n",
            "you have received your program with\n",
            "you have received your program will\n",
            "you have received your program will\n",
            "you have received your program wilk\n",
            "you have received your program with\n",
            "you have received your program with\n",
            "you have received your program will\n",
            "you have received your program will\n",
            "you have received your program will\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"you have receiv\",temp=1,mode='sto')\n",
        "for i in range(salidas.shape[0]):\n",
        "    print(decode(salidas[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you have receive your account for y\n",
            "you have receive your account for a\n",
            "you have receive your account for y\n",
            "you have receive your account for y\n",
            "you have receive your account for y\n",
            "you have receive your account for y\n",
            "you have receive your account for a\n",
            "you have receive your account for y\n",
            "you have receive your account for y\n",
            "you have receive your account for y\n"
          ]
        }
      ],
      "source": [
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"you have receiv\",temp=0.33,mode='sto')\n",
        "for i in range(salidas.shape[0]):\n",
        "    print(decode(salidas[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are some question with you have to \n",
            "there are some question with you have atu\n",
            "there are some question with you have a m\n",
            "there are some question with you have and\n",
            "there are some question with you have at \n",
            "there are some question with you have and\n",
            "there are some question with you have bal\n",
            "there are some question with you have and\n",
            "there are some question with you have and\n",
            "there are some question with you have ano\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"there are some questi\",temp=1,mode='sto')\n",
        "for i in range(salidas.shape[0]):\n",
        "    print(decode(salidas[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are some questions to your project \n",
            "there are some questions to your projects\n",
            "there are some questions to your project \n",
            "there are some questions to your projects\n",
            "there are some questions to your projecti\n",
            "there are some questions to your project \n",
            "there are some questions to your project \n",
            "there are some questions to your projects\n",
            "there are some questions to your project \n",
            "there are some questions to your project \n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"there are some questi\",temp=0.33,mode='sto')\n",
        "for i in range(salidas.shape[0]):\n",
        "    print(decode(salidas[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se comprueba en estas pruebas que el valor de tempratura influye directamente sobre la variabilidad de la salida generada, haciendo que a tempraturas más frias el modelo tienda a devolver siempre la misma salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear colleage company logo Custo\n",
            "Dear colleage.                  \n",
            "Dear colleage company logo Casto\n",
            "Dear colleage company logo Servi\n",
            "Dear colleage company logo Casti\n",
            "Dear colleage company logo Compa\n",
            "Dear colleage company logo Custi\n",
            "Dear colleage company logo Call \n",
            "Dear colleage company logo Caste\n",
            "Dear colleage company logo Conte\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search\n",
        "salidas = beam_search(model,num_beams=10,num_words=20,input=\"Dear colleag\",temp=1,mode='det')\n",
        "for i in range(salidas.shape[0]):\n",
        "    print(decode(salidas[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modo determinista bloquea parte de la aleatoriedad de la salida, devolviendo siempre el mismo conjunto de resultados sin importar las veces que lo ejecutemos. Esto no ocurre en el modo estocástico, el cual devuelve valores distintos cada vez que se ejecuta el mismo código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusiones\n",
        "En este desafío hemos comprobado la capacidad de los modelos de lenguaje de caracteres para analizar una secuencia dada y ser capaz de completar la palabra incompleta. Sin embargo, se vuelve muy inestable a la hora de predecir la continuación de la frase, por lo que en estos casos conviene el uso de modelos de lenguaje especializados en palabras.\n",
        "\n",
        "Es muy notable la diferencia entre los recursos necesarios para entrenar una modelo centrado en caracteres frente al de palabras. El segundo caso requiere un mayor volumen de datos, hiperparámetros y tiempo de entrenamiento, suponiendo un gran reto para aquellos desarrolladores que no posean suficiente capacidad de hardware"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
