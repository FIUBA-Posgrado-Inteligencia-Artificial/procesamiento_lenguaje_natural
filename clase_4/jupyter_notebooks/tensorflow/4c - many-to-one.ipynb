{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4c - many-to-one.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMb9RFL4766yk5FBqcH7Zry"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NEnBiuLcukJc"},"source":["<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## RNN many-to-one"]},{"cell_type":"markdown","metadata":{"id":"i96B2RF8uqEb"},"source":["#### Datos\n","El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n","[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"]},{"cell_type":"code","metadata":{"id":"Lx0HQ-1RvJw9"},"source":["import re\n","\n","import numpy as np\n","import pandas as pd\n","\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM\n","from keras.layers import GlobalMaxPooling1D\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","from keras.layers import Bidirectional"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10bFkG1YuaD9"},"source":["# Generar datos sintéticos\n","X = list()\n","y = list()\n","\n","# X será una lista de 1 a 45 agrupado de a 3 números consecutivos\n","# [ [1, 2, 3], [4, 5, 6], ....]\n","X = [ [x, x+1, x+2] for x in range(1, 46, 3)]\n","\n","# \"y\" (target) se obtiene como la suma de cada grupo de 3 números de entrada\n","y = [sum(x) for x in X]\n","\n","print(\"datos X:\", X)\n","print(\"datos y:\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oqabd-kYvza9"},"source":["# Cada dato X lo transformarmos en una matriz de 1 fila 1 columna (1x1)\n","X = np.array(X).reshape(len(X), len(X[0]), 1)\n","print(\"datos X:\", X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gYz6XpuyxBbQ"},"source":["y = np.asanyarray(y)\n","y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VG3-d_NXwDGD"},"source":["### 2 - Entrenar el modelo"]},{"cell_type":"code","metadata":{"id":"OFeZEc63wOvJ"},"source":["input_shape = X[0].shape\n","input_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZir-NqDwWEo"},"source":["output_shape = 1\n","output_shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAhw8O9mwLR0"},"source":["model = Sequential()\n","model.add(LSTM(64, activation='relu', input_shape=input_shape))\n","model.add(Dense(output_shape))\n","model.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSX93pkow2zM"},"source":["hist = model.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anuBmCv0xNGA"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88tdVCOyxcuy"},"source":["# Ensayo\n","x_test = [50, 51, 52]\n","y_test = sum(x_test)\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, len(x_test), 1))\n","y_hat = model.predict(test_input, verbose=0)[0][0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AT8b9EfGyshD"},"source":["### 3 - Bidirectional RNN (BRNN)"]},{"cell_type":"code","metadata":{"id":"cH8Yd6WYyzQQ"},"source":["# En esta oportunidad se utilizará Bidirectional, dentro se especifica\n","# que lo que se desea hacer bidireccional es una capa LSTM\n","\n","# En el summary se puede observar que la cantidad de parámetros\n","# de nuestor nueva capa LSTM bidireccional es el doble que la anterior\n","\n","model2 = Sequential()\n","model2.add(Bidirectional(LSTM(64, activation='relu'), input_shape=input_shape))\n","model2.add(Dense(output_shape))\n","model2.compile(loss='mse',\n","              optimizer=\"Adam\")\n","\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLtlpYpxzQZr"},"source":["hist2 = model2.fit(X, y, epochs=500, validation_split=0.2, batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3Sl3cUJzZV_"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Entrenamiento\n","epoch_count = range(1, len(hist2.history['loss']) + 1)\n","sns.lineplot(x=epoch_count,  y=hist2.history['loss'], label='train')\n","sns.lineplot(x=epoch_count,  y=hist2.history['val_loss'], label='valid')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FveVOv2xzfkC"},"source":["# Ensayo\n","x_test = [50, 51, 52]\n","y_test = sum(x_test)\n","test_input = np.array([x_test])\n","test_input = test_input.reshape((1, len(x_test), 1))\n","y_hat = model2.predict(test_input, verbose=0)[0][0]\n","\n","print(\"y_test:\", y_test)\n","print(\"y_hat:\", y_hat)\n","\n","model2.evaluate(test_input, np.array([y_test]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zd1g5MZfz5qB"},"source":["### 4 - Conclusión\n","Implementar un modelo bidireccional basado en RNN (en este caso LSTM) es muy sensillo. En este ejemplo no se explotó su potencialidad pero queda como nota de como implementar una capa BRNN."]}]}