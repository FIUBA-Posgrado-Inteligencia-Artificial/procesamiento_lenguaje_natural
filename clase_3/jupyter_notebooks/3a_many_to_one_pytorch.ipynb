{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEnBiuLcukJc"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## RNN many-to-one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i96B2RF8uqEb"
      },
      "source": [
        "#### Datos\n",
        "El objecto es utilizar una serie de sucuencias númericas (datos sintéticos) para poner a prueba el uso de las redes RNN. Este ejemplo se inspiró en otro artículo, lo tienen como referencia en el siguiente link:\\\n",
        "[LINK](https://stackabuse.com/solving-sequence-problems-with-lstm-in-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lx0HQ-1RvJw9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "10bFkG1YuaD9",
        "outputId": "1086d8f8-13a1-4146-89a5-7d2c91aca458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datos X: [[[ 1]\n",
            "  [ 2]\n",
            "  [ 3]]\n",
            "\n",
            " [[ 4]\n",
            "  [ 5]\n",
            "  [ 6]]\n",
            "\n",
            " [[ 7]\n",
            "  [ 8]\n",
            "  [ 9]]\n",
            "\n",
            " [[10]\n",
            "  [11]\n",
            "  [12]]\n",
            "\n",
            " [[13]\n",
            "  [14]\n",
            "  [15]]\n",
            "\n",
            " [[16]\n",
            "  [17]\n",
            "  [18]]\n",
            "\n",
            " [[19]\n",
            "  [20]\n",
            "  [21]]\n",
            "\n",
            " [[22]\n",
            "  [23]\n",
            "  [24]]\n",
            "\n",
            " [[25]\n",
            "  [26]\n",
            "  [27]]\n",
            "\n",
            " [[28]\n",
            "  [29]\n",
            "  [30]]\n",
            "\n",
            " [[31]\n",
            "  [32]\n",
            "  [33]]\n",
            "\n",
            " [[34]\n",
            "  [35]\n",
            "  [36]]\n",
            "\n",
            " [[37]\n",
            "  [38]\n",
            "  [39]]\n",
            "\n",
            " [[40]\n",
            "  [41]\n",
            "  [42]]\n",
            "\n",
            " [[43]\n",
            "  [44]\n",
            "  [45]]]\n",
            "datos y: [[  6]\n",
            " [ 15]\n",
            " [ 24]\n",
            " [ 33]\n",
            " [ 42]\n",
            " [ 51]\n",
            " [ 60]\n",
            " [ 69]\n",
            " [ 78]\n",
            " [ 87]\n",
            " [ 96]\n",
            " [105]\n",
            " [114]\n",
            " [123]\n",
            " [132]]\n"
          ]
        }
      ],
      "source": [
        "# Generar datos sintéticos\n",
        "X = list()\n",
        "y = list()\n",
        "\n",
        "# X será una lista de 1 a 45 agrupado de a 3 números consecutivos\n",
        "# [ [1, 2, 3], [4, 5, 6], ....]\n",
        "X = [ [x, x+1, x+2] for x in range(1, 46, 3)]\n",
        "\n",
        "# \"y\" (target) se obtiene como la suma de cada grupo de 3 números de entrada\n",
        "y = [sum(x) for x in X]\n",
        "\n",
        "X = np.array(X).reshape(len(X), 3, 1)   # (n_samples, seq_len, n_features)\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "\n",
        "print(\"datos X:\", X)\n",
        "print(\"datos y:\", y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Oqabd-kYvza9"
      },
      "outputs": [],
      "source": [
        "# Train/valid split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Los pasamos a tensores para poder meterlos a la RRN\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gYz6XpuyxBbQ",
        "outputId": "369cba43-ccf6-4a80-e5dc-ed6c8ada9019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y = np.asanyarray(y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3-d_NXwDGD"
      },
      "source": [
        "### 2 - Entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OFeZEc63wOvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c485796d-f246-42db-e0a9-005c693f341a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "input_shape = X[0].shape\n",
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RZir-NqDwWEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d660320-541e-46bb-e680-272e0ab54cc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "output_shape = 1\n",
        "output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QAhw8O9mwLR0"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, output_size=1, bidirectional=False):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
        "        self.fc = nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]   # última salida de la secuencia\n",
        "        out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model_es(model, X_train, y_train, X_val, y_val,\n",
        "                   epochs=500, batch_size=5, lr=0.005,\n",
        "                   patience=60, min_delta=1e-4):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "\n",
        "    n_samples = X_train.shape[0]\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        perm = torch.randperm(n_samples)\n",
        "        batch_losses = []\n",
        "\n",
        "        for i in range(0, n_samples, batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            xb, yb = X_train[idx], y_train[idx]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(xb)\n",
        "            loss = criterion(outputs, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "        # Validación\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = model(X_val)\n",
        "            val_loss = criterion(val_pred, y_val).item()\n",
        "\n",
        "        train_loss_mean = np.mean(batch_losses)\n",
        "        history[\"train_loss\"].append(train_loss_mean)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss + min_delta < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping en epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        if (epoch+1) % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss_mean:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Restaurar mejor modelo\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "hBC9fRzHWt4g"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uSX93pkow2zM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "7a5fc7ac-967d-4352-f9d5-6c3aa8e4aedc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 64x1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1993911215.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2352860033.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1257038046.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m   \u001b[0;34m]\u001b[0m          \u001b[0;31m# última salida de la secuencia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# equivalente a activation='relu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 64x1)"
          ]
        }
      ],
      "source": [
        "\n",
        "model1 = LSTMModel()\n",
        "hist1 = train_model_es(model1, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anuBmCv0xNGA"
      },
      "outputs": [],
      "source": [
        "#Curva de entrenamiento\n",
        "plt.plot(hist1[\"train_loss\"], label=\"train\")\n",
        "plt.plot(hist1[\"val_loss\"], label=\"valid\")\n",
        "plt.legend()\n",
        "plt.title(\"LSTM \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88tdVCOyxcuy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensayo\n",
        "x_test = np.array([[50, 51, 52]]).reshape((1, 3, 1))\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor([[sum([50, 51, 52])]], dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_hat1 = model1(x_test).item()\n",
        "\n",
        "print(\"Modelo Simple y_test:\", y_test.item(), \"y_hat:\", y_hat1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT8b9EfGyshD"
      },
      "source": [
        "### 3 - Bidirectional RNN (BRNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH8Yd6WYyzQQ"
      },
      "outputs": [],
      "source": [
        "# En esta oportunidad se utilizará Bidirectional, dentro se especifica\n",
        "# que lo que se desea hacer bidireccional es una capa LSTM\n",
        "\n",
        "# En el summary se puede observar que la cantidad de parámetros\n",
        "# de nuestor nueva capa LSTM bidireccional es el doble que la anterior\n",
        "\n",
        "model2 = LSTMModel(bidir=True)\n",
        "\n",
        "\n",
        "model2 = LSTMModel(bidirectional=True)\n",
        "hist2 = train_model_es(model2, X_train, y_train, X_val, y_val)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_hat2 = model2(x_test).item()\n",
        "\n",
        "print(\"y_test:\", y_test.item())\n",
        "print(\"y_hat (bidirectional):\", y_hat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLtlpYpxzQZr"
      },
      "outputs": [],
      "source": [
        "hist2 = train_model(model2, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3Sl3cUJzZV_"
      },
      "outputs": [],
      "source": [
        "plt.plot(hist2[\"train_loss\"], label=\"train\")\n",
        "plt.plot(hist2[\"val_loss\"], label=\"valid\")\n",
        "plt.legend()\n",
        "plt.title(\"LSTM Bidireccional\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FveVOv2xzfkC"
      },
      "outputs": [],
      "source": [
        "# Ensayo\n",
        "x_test = np.array([[50, 51, 52]]).reshape((1, 3, 1))\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor([[sum([50, 51, 52])]], dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_hat2 = model2(x_test).item()\n",
        "\n",
        "print(\"Modelo Bidireccional y_test:\", y_test.item(), \"y_hat:\", y_hat2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd1g5MZfz5qB"
      },
      "source": [
        "### 4 - Conclusión\n",
        "Implementar un modelo bidireccional basado en RNN (en este caso LSTM) es muy sensillo. En este ejemplo no se explotó su potencialidad pero queda como nota de como implementar una capa BRNN."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "4c - many-to-one.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
